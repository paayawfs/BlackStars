{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ“Š Football Player Analytics Pipeline\n",
                "## Notebook 3: K-Means Clustering\n",
                "\n",
                "This notebook clusters forwards based on their statistical profiles.\n",
                "\n",
                "**Important**: We don't assign fancy names - we describe what each cluster actually does based on the data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from pathlib import Path\n",
                "import pickle\n",
                "\n",
                "from sklearn.cluster import KMeans\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import silhouette_score\n",
                "from sklearn.decomposition import PCA\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "DATA_DIR = Path(\"../data\")\n",
                "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
                "OUTPUT_DIR = Path(\"../outputs\")\n",
                "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "print(\"âœ… Libraries loaded!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load processed forwards\n",
                "data_file = PROCESSED_DIR / \"forwards_processed.csv\"\n",
                "\n",
                "if not data_file.exists():\n",
                "    raise FileNotFoundError(f\"Run Notebook 02 first! Missing: {data_file}\")\n",
                "\n",
                "df = pd.read_csv(data_file)\n",
                "print(f\"âœ… Loaded {len(df)} forwards\")\n",
                "print(f\"\\nðŸ“‹ Available columns: {len(df.columns)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load or find clustering features\n",
                "feature_file = PROCESSED_DIR / \"clustering_features.txt\"\n",
                "if feature_file.exists():\n",
                "    with open(feature_file, 'r') as f:\n",
                "        CLUSTERING_FEATURES = [line.strip() for line in f.readlines() if line.strip()]\n",
                "else:\n",
                "    # Find all per90 columns that aren't normalized versions\n",
                "    CLUSTERING_FEATURES = [c for c in df.columns if 'per90' in c.lower() and '_norm' not in c]\n",
                "\n",
                "print(f\"\\nðŸ“Š Using {len(CLUSTERING_FEATURES)} features for clustering:\")\n",
                "for i, f in enumerate(CLUSTERING_FEATURES, 1):\n",
                "    print(f\"  {i}. {f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Prepare Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create feature matrix\n",
                "X = df[CLUSTERING_FEATURES].fillna(0).values\n",
                "\n",
                "# Standardize\n",
                "scaler = StandardScaler()\n",
                "X_scaled = scaler.fit_transform(X)\n",
                "\n",
                "print(f\"ðŸ“Š Feature matrix: {X_scaled.shape[0]} players Ã— {X_scaled.shape[1]} features\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Find Optimal Clusters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test k from 4 to 12\n",
                "K_RANGE = range(4, 13)\n",
                "results = []\n",
                "\n",
                "print(\"Testing cluster counts...\\n\")\n",
                "for k in K_RANGE:\n",
                "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=15)\n",
                "    labels = kmeans.fit_predict(X_scaled)\n",
                "    sil = silhouette_score(X_scaled, labels)\n",
                "    results.append({'k': k, 'silhouette': sil, 'inertia': kmeans.inertia_})\n",
                "    print(f\"  k={k:2d}: silhouette={sil:.3f}\")\n",
                "\n",
                "results_df = pd.DataFrame(results)\n",
                "best_k = results_df.loc[results_df['silhouette'].idxmax(), 'k']\n",
                "print(f\"\\nâœ… Best k = {int(best_k)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot\n",
                "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
                "ax[0].plot(results_df['k'], results_df['inertia'], 'b-o')\n",
                "ax[0].set_xlabel('k'); ax[0].set_ylabel('Inertia'); ax[0].set_title('Elbow Method')\n",
                "ax[1].plot(results_df['k'], results_df['silhouette'], 'g-o')\n",
                "ax[1].axvline(x=best_k, color='r', linestyle='--')\n",
                "ax[1].set_xlabel('k'); ax[1].set_ylabel('Silhouette'); ax[1].set_title('Silhouette Score')\n",
                "plt.tight_layout()\n",
                "plt.savefig(OUTPUT_DIR / 'cluster_evaluation.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Choose number of clusters (you can change this)\n",
                "N_CLUSTERS = 7  # Adjust based on above analysis\n",
                "print(f\"\\nðŸŽ¯ Using {N_CLUSTERS} clusters\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Run Clustering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fit final model\n",
                "kmeans = KMeans(n_clusters=N_CLUSTERS, random_state=42, n_init=20)\n",
                "df['cluster'] = kmeans.fit_predict(X_scaled)\n",
                "\n",
                "print(\"âœ… Clustering complete!\")\n",
                "print(f\"\\nPlayers per cluster:\")\n",
                "print(df['cluster'].value_counts().sort_index())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Describe Each Cluster\n",
                "\n",
                "For each cluster, we show:\n",
                "- How many players\n",
                "- Which stats are HIGH (above average)\n",
                "- Which stats are LOW (below average)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate z-scores for each cluster\n",
                "overall_mean = df[CLUSTERING_FEATURES].mean()\n",
                "overall_std = df[CLUSTERING_FEATURES].std()\n",
                "\n",
                "cluster_profiles = df.groupby('cluster')[CLUSTERING_FEATURES].mean()\n",
                "cluster_zscores = (cluster_profiles - overall_mean) / overall_std\n",
                "\n",
                "print(\"ðŸ“Š Cluster Z-Scores (green=high, red=low):\")\n",
                "styled = cluster_zscores.style.background_gradient(cmap='RdYlGn', axis=None, vmin=-2, vmax=2)\n",
                "display(styled)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create descriptive labels (no cute names, just what they do)\n",
                "def describe_cluster(z_scores: pd.Series) -> str:\n",
                "    \"\"\"\n",
                "    Create a description based on what the cluster is high/low in.\n",
                "    No fancy names - just factual descriptions.\n",
                "    \"\"\"\n",
                "    # Get high and low traits\n",
                "    high_traits = z_scores[z_scores > 0.5].sort_values(ascending=False)\n",
                "    low_traits = z_scores[z_scores < -0.5].sort_values()\n",
                "    \n",
                "    # Build description\n",
                "    parts = []\n",
                "    \n",
                "    if len(high_traits) > 0:\n",
                "        high_names = [t.replace('_per90', '').replace('_', ' ') for t in high_traits.index[:3]]\n",
                "        parts.append(f\"HIGH: {', '.join(high_names)}\")\n",
                "    \n",
                "    if len(low_traits) > 0:\n",
                "        low_names = [t.replace('_per90', '').replace('_', ' ') for t in low_traits.index[:2]]\n",
                "        parts.append(f\"LOW: {', '.join(low_names)}\")\n",
                "    \n",
                "    if not parts:\n",
                "        return \"Average across all metrics\"\n",
                "    \n",
                "    return \" | \".join(parts)\n",
                "\n",
                "# Describe each cluster\n",
                "cluster_descriptions = {}\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"CLUSTER DESCRIPTIONS (based on statistical analysis)\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "for cluster_id in range(N_CLUSTERS):\n",
                "    z_scores = cluster_zscores.loc[cluster_id]\n",
                "    description = describe_cluster(z_scores)\n",
                "    count = (df['cluster'] == cluster_id).sum()\n",
                "    \n",
                "    cluster_descriptions[cluster_id] = f\"Cluster {cluster_id}: {description}\"\n",
                "    \n",
                "    print(f\"\\nCluster {cluster_id} ({count} players)\")\n",
                "    print(\"-\" * 60)\n",
                "    print(description)\n",
                "    \n",
                "    # Show actual values\n",
                "    print(\"\\nKey metrics:\")\n",
                "    for feat in CLUSTERING_FEATURES:\n",
                "        z = z_scores[feat]\n",
                "        val = cluster_profiles.loc[cluster_id, feat]\n",
                "        if abs(z) > 0.3:  # Only show notable differences\n",
                "            direction = \"â†‘\" if z > 0 else \"â†“\"\n",
                "            print(f\"  {direction} {feat}: {val:.3f} (z={z:+.2f})\")\n",
                "\n",
                "# Add descriptions to dataframe\n",
                "df['cluster_name'] = df['cluster'].map(cluster_descriptions)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Heatmap of cluster profiles\n",
                "fig, ax = plt.subplots(figsize=(14, 8))\n",
                "\n",
                "# Clean column names for display\n",
                "display_cols = [c.replace('_per90', '').replace('_', ' ').title() for c in CLUSTERING_FEATURES]\n",
                "plot_data = cluster_zscores.copy()\n",
                "plot_data.columns = display_cols\n",
                "plot_data.index = [f\"Cluster {i}\" for i in plot_data.index]\n",
                "\n",
                "sns.heatmap(plot_data, annot=True, fmt='.2f', cmap='RdYlGn', center=0,\n",
                "            vmin=-2, vmax=2, ax=ax, cbar_kws={'label': 'Z-Score'})\n",
                "\n",
                "ax.set_title('Cluster Profiles (Z-Score: how different from average)', fontsize=14, fontweight='bold')\n",
                "ax.set_xlabel('Features')\n",
                "ax.set_ylabel('Cluster')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(OUTPUT_DIR / 'cluster_heatmap.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Visualize (2D PCA)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# PCA for 2D visualization\n",
                "pca = PCA(n_components=2)\n",
                "X_pca = pca.fit_transform(X_scaled)\n",
                "df['pca_1'] = X_pca[:, 0]\n",
                "df['pca_2'] = X_pca[:, 1]\n",
                "\n",
                "print(f\"PCA explains {pca.explained_variance_ratio_.sum()*100:.1f}% of variance\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Scatter plot\n",
                "fig, ax = plt.subplots(figsize=(12, 8))\n",
                "\n",
                "for cluster_id in range(N_CLUSTERS):\n",
                "    mask = df['cluster'] == cluster_id\n",
                "    count = mask.sum()\n",
                "    ax.scatter(df.loc[mask, 'pca_1'], df.loc[mask, 'pca_2'], \n",
                "               label=f'Cluster {cluster_id} (n={count})', alpha=0.6, s=30)\n",
                "\n",
                "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)')\n",
                "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)')\n",
                "ax.set_title('Forward Clusters (PCA Projection)')\n",
                "ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left')\n",
                "ax.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(OUTPUT_DIR / 'cluster_scatter.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Sample Players"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Show sample players from each cluster\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"SAMPLE PLAYERS BY CLUSTER\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "for cluster_id in range(N_CLUSTERS):\n",
                "    cluster_df = df[df['cluster'] == cluster_id]\n",
                "    print(f\"\\nCluster {cluster_id} ({len(cluster_df)} players)\")\n",
                "    print(\"-\" * 40)\n",
                "    \n",
                "    # Sort by a key metric and show top 5\n",
                "    sort_col = 'goals_per90' if 'goals_per90' in df.columns else CLUSTERING_FEATURES[0]\n",
                "    top = cluster_df.nlargest(5, sort_col)\n",
                "    \n",
                "    for _, row in top.iterrows():\n",
                "        player = row.get('player', 'Unknown')\n",
                "        team = row.get('team', '')\n",
                "        league = row.get('league', '')\n",
                "        print(f\"  â€¢ {player} ({team}, {league})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Save Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save clustered data\n",
                "output_file = PROCESSED_DIR / \"forwards_clustered.csv\"\n",
                "df.to_csv(output_file, index=False)\n",
                "print(f\"ðŸ’¾ Saved: {output_file}\")\n",
                "\n",
                "# Save model\n",
                "model_data = {\n",
                "    'kmeans': kmeans,\n",
                "    'scaler': scaler,\n",
                "    'pca': pca,\n",
                "    'features': CLUSTERING_FEATURES,\n",
                "    'cluster_names': cluster_descriptions,\n",
                "    'cluster_profiles': cluster_profiles,\n",
                "    'cluster_zscores': cluster_zscores,\n",
                "    'n_clusters': N_CLUSTERS\n",
                "}\n",
                "\n",
                "with open(OUTPUT_DIR / \"clustering_model.pkl\", 'wb') as f:\n",
                "    pickle.dump(model_data, f)\n",
                "print(f\"ðŸ’¾ Saved: clustering_model.pkl\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## âœ… Done! Now run Notebook 04 for Ghana analysis."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}