{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üìä Football Player Analytics Pipeline\n",
                "## Notebook 3b: Hierarchical Clustering\n",
                "\n",
                "This notebook explores **Hierarchical Clustering** as an alternative to K-Means.\n",
                "\n",
                "**Key advantages of Hierarchical Clustering:**\n",
                "- Creates a tree-like structure (dendrogram) showing how players relate\n",
                "- No need to specify k upfront\n",
                "- Reveals nested groupings (sub-clusters within clusters)\n",
                "- Better interpretability of cluster relationships"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from pathlib import Path\n",
                "import pickle\n",
                "\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import silhouette_score\n",
                "from sklearn.decomposition import PCA\n",
                "\n",
                "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
                "from scipy.spatial.distance import pdist\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "DATA_DIR = Path(\"../data\")\n",
                "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
                "OUTPUT_DIR = Path(\"../outputs\")\n",
                "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "print(\"‚úÖ Libraries loaded!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load processed forwards\n",
                "data_file = PROCESSED_DIR / \"forwards_processed.csv\"\n",
                "\n",
                "if not data_file.exists():\n",
                "    raise FileNotFoundError(f\"Run Notebook 02 first! Missing: {data_file}\")\n",
                "\n",
                "df = pd.read_csv(data_file)\n",
                "print(f\"‚úÖ Loaded {len(df)} forwards\")\n",
                "print(f\"\\nüìã Available columns: {len(df.columns)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Identify key columns (case-insensitive)\n",
                "def find_col(df, names):\n",
                "    \"\"\"Find column by name, case-insensitive.\"\"\"\n",
                "    for name in names:\n",
                "        for col in df.columns:\n",
                "            if col.lower() == name.lower():\n",
                "                return col\n",
                "    return None\n",
                "\n",
                "PLAYER_COL = find_col(df, ['Player', 'player', 'Name', 'name'])\n",
                "TEAM_COL = find_col(df, ['Squad', 'squad', 'Team', 'team'])\n",
                "LEAGUE_COL = find_col(df, ['League', 'league', 'Comp', 'comp'])\n",
                "\n",
                "print(f\"Player column: {PLAYER_COL}\")\n",
                "print(f\"Team column: {TEAM_COL}\")\n",
                "print(f\"League column: {LEAGUE_COL}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load or find clustering features\n",
                "feature_file = PROCESSED_DIR / \"clustering_features.txt\"\n",
                "if feature_file.exists():\n",
                "    with open(feature_file, 'r') as f:\n",
                "        CLUSTERING_FEATURES = [line.strip() for line in f.readlines() if line.strip()]\n",
                "else:\n",
                "    # Find all per90 columns that aren't normalized versions\n",
                "    CLUSTERING_FEATURES = [c for c in df.columns if 'per90' in c.lower() and '_norm' not in c]\n",
                "\n",
                "print(f\"\\nüìä Using {len(CLUSTERING_FEATURES)} features for clustering:\")\n",
                "for i, f in enumerate(CLUSTERING_FEATURES, 1):\n",
                "    print(f\"  {i}. {f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Prepare Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create feature matrix\n",
                "X = df[CLUSTERING_FEATURES].fillna(0).values\n",
                "\n",
                "# Standardize\n",
                "scaler = StandardScaler()\n",
                "X_scaled = scaler.fit_transform(X)\n",
                "\n",
                "print(f\"üìä Feature matrix: {X_scaled.shape[0]} players √ó {X_scaled.shape[1]} features\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Compute Hierarchical Clustering\n",
                "\n",
                "We'll try different **linkage methods**:\n",
                "- `ward`: Minimizes variance within clusters (most common)\n",
                "- `average`: Uses average distance between all pairs\n",
                "- `complete`: Uses maximum distance between clusters\n",
                "- `single`: Uses minimum distance between clusters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute linkage matrices for different methods\n",
                "linkage_methods = ['ward', 'average', 'complete']\n",
                "linkage_results = {}\n",
                "\n",
                "for method in linkage_methods:\n",
                "    print(f\"Computing {method} linkage...\")\n",
                "    if method == 'ward':\n",
                "        Z = linkage(X_scaled, method=method)\n",
                "    else:\n",
                "        # For non-ward methods, we can use different distance metrics\n",
                "        Z = linkage(X_scaled, method=method, metric='euclidean')\n",
                "    linkage_results[method] = Z\n",
                "\n",
                "print(\"\\n‚úÖ All linkage matrices computed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Visualize Dendrograms\n",
                "\n",
                "A dendrogram shows how clusters are formed at each level."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot dendrograms for each method\n",
                "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
                "\n",
                "for ax, method in zip(axes, linkage_methods):\n",
                "    dendrogram(\n",
                "        linkage_results[method],\n",
                "        truncate_mode='lastp',  # Show only last p merged clusters\n",
                "        p=30,  # Show 30 clusters\n",
                "        leaf_rotation=90,\n",
                "        leaf_font_size=8,\n",
                "        ax=ax\n",
                "    )\n",
                "    ax.set_title(f'{method.capitalize()} Linkage', fontsize=14, fontweight='bold')\n",
                "    ax.set_xlabel('Cluster Size')\n",
                "    ax.set_ylabel('Distance')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(OUTPUT_DIR / 'hierarchical_dendrograms.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Full dendrogram with Ward linkage (zoomed out view)\n",
                "plt.figure(figsize=(16, 8))\n",
                "\n",
                "dendrogram(\n",
                "    linkage_results['ward'],\n",
                "    truncate_mode='level',\n",
                "    p=5,  # Show 5 levels\n",
                "    show_contracted=True,\n",
                "    leaf_rotation=90,\n",
                "    leaf_font_size=8\n",
                ")\n",
                "\n",
                "plt.title('Ward Linkage Dendrogram (Truncated)', fontsize=14, fontweight='bold')\n",
                "plt.xlabel('Sample Index or (Cluster Size)')\n",
                "plt.ylabel('Distance')\n",
                "\n",
                "# Add horizontal lines for potential cuts\n",
                "plt.axhline(y=40, color='r', linestyle='--', alpha=0.5, label='Potential cut (k=5-7)')\n",
                "plt.axhline(y=25, color='orange', linestyle='--', alpha=0.5, label='Potential cut (k=8-10)')\n",
                "plt.legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(OUTPUT_DIR / 'hierarchical_dendrogram_full.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Choose Optimal Number of Clusters\n",
                "\n",
                "We'll use silhouette score to find the best cut."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test different numbers of clusters\n",
                "K_RANGE = range(4, 13)\n",
                "results = []\n",
                "\n",
                "# Using Ward linkage (generally best for compact clusters)\n",
                "Z_ward = linkage_results['ward']\n",
                "\n",
                "print(\"Testing cluster counts...\\n\")\n",
                "for k in K_RANGE:\n",
                "    labels = fcluster(Z_ward, k, criterion='maxclust')\n",
                "    sil = silhouette_score(X_scaled, labels)\n",
                "    results.append({'k': k, 'silhouette': sil, 'method': 'ward'})\n",
                "    print(f\"  k={k:2d}: silhouette={sil:.3f}\")\n",
                "\n",
                "results_df = pd.DataFrame(results)\n",
                "best_k = int(results_df.loc[results_df['silhouette'].idxmax(), 'k'])\n",
                "print(f\"\\n‚úÖ Best k = {best_k}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compare linkage methods across different k values\n",
                "comparison_results = []\n",
                "\n",
                "for method in linkage_methods:\n",
                "    Z = linkage_results[method]\n",
                "    for k in K_RANGE:\n",
                "        labels = fcluster(Z, k, criterion='maxclust')\n",
                "        sil = silhouette_score(X_scaled, labels)\n",
                "        comparison_results.append({'k': k, 'silhouette': sil, 'method': method})\n",
                "\n",
                "comparison_df = pd.DataFrame(comparison_results)\n",
                "\n",
                "# Plot comparison\n",
                "fig, ax = plt.subplots(figsize=(10, 5))\n",
                "for method in linkage_methods:\n",
                "    data = comparison_df[comparison_df['method'] == method]\n",
                "    ax.plot(data['k'], data['silhouette'], '-o', label=method.capitalize())\n",
                "\n",
                "ax.axvline(x=best_k, color='gray', linestyle='--', alpha=0.5, label=f'Best k={best_k}')\n",
                "ax.set_xlabel('Number of Clusters (k)')\n",
                "ax.set_ylabel('Silhouette Score')\n",
                "ax.set_title('Linkage Method Comparison')\n",
                "ax.legend()\n",
                "ax.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(OUTPUT_DIR / 'hierarchical_method_comparison.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Choose number of clusters (you can adjust this)\n",
                "N_CLUSTERS = best_k  # Use the best k found, or manually set\n",
                "LINKAGE_METHOD = 'ward'  # Best for balanced, compact clusters\n",
                "\n",
                "print(f\"\\nüéØ Using {N_CLUSTERS} clusters with {LINKAGE_METHOD} linkage\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Apply Final Clustering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get cluster assignments\n",
                "Z_final = linkage_results[LINKAGE_METHOD]\n",
                "df['cluster'] = fcluster(Z_final, N_CLUSTERS, criterion='maxclust') - 1  # Zero-indexed\n",
                "\n",
                "print(\"‚úÖ Hierarchical clustering complete!\")\n",
                "print(f\"\\nPlayers per cluster:\")\n",
                "print(df['cluster'].value_counts().sort_index())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Describe Each Cluster\n",
                "\n",
                "Same approach as K-Means: describe based on statistical profiles."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate z-scores for each cluster\n",
                "overall_mean = df[CLUSTERING_FEATURES].mean()\n",
                "overall_std = df[CLUSTERING_FEATURES].std()\n",
                "\n",
                "cluster_profiles = df.groupby('cluster')[CLUSTERING_FEATURES].mean()\n",
                "cluster_zscores = (cluster_profiles - overall_mean) / overall_std\n",
                "\n",
                "print(\"üìä Cluster Z-Scores (green=high, red=low):\")\n",
                "styled = cluster_zscores.style.background_gradient(cmap='RdYlGn', axis=None, vmin=-2, vmax=2)\n",
                "display(styled)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create descriptive labels\n",
                "def describe_cluster(z_scores: pd.Series) -> str:\n",
                "    \"\"\"\n",
                "    Create a description based on what the cluster is high/low in.\n",
                "    No fancy names - just factual descriptions.\n",
                "    \"\"\"\n",
                "    high_traits = z_scores[z_scores > 0.5].sort_values(ascending=False)\n",
                "    low_traits = z_scores[z_scores < -0.5].sort_values()\n",
                "    \n",
                "    parts = []\n",
                "    \n",
                "    if len(high_traits) > 0:\n",
                "        high_names = [t.replace('_per90', '').replace('_', ' ') for t in high_traits.index[:3]]\n",
                "        parts.append(f\"HIGH: {', '.join(high_names)}\")\n",
                "    \n",
                "    if len(low_traits) > 0:\n",
                "        low_names = [t.replace('_per90', '').replace('_', ' ') for t in low_traits.index[:2]]\n",
                "        parts.append(f\"LOW: {', '.join(low_names)}\")\n",
                "    \n",
                "    if not parts:\n",
                "        return \"Average across all metrics\"\n",
                "    \n",
                "    return \" | \".join(parts)\n",
                "\n",
                "# Describe each cluster\n",
                "cluster_descriptions = {}\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"CLUSTER DESCRIPTIONS (Hierarchical - based on statistical analysis)\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "for cluster_id in range(N_CLUSTERS):\n",
                "    z_scores = cluster_zscores.loc[cluster_id]\n",
                "    description = describe_cluster(z_scores)\n",
                "    count = (df['cluster'] == cluster_id).sum()\n",
                "    \n",
                "    cluster_descriptions[cluster_id] = f\"Cluster {cluster_id}: {description}\"\n",
                "    \n",
                "    print(f\"\\nCluster {cluster_id} ({count} players)\")\n",
                "    print(\"-\" * 60)\n",
                "    print(description)\n",
                "    \n",
                "    # Show key metrics\n",
                "    print(\"\\nKey metrics:\")\n",
                "    for feat in CLUSTERING_FEATURES:\n",
                "        z = z_scores[feat]\n",
                "        val = cluster_profiles.loc[cluster_id, feat]\n",
                "        if abs(z) > 0.3:\n",
                "            direction = \"‚Üë\" if z > 0 else \"‚Üì\"\n",
                "            print(f\"  {direction} {feat}: {val:.3f} (z={z:+.2f})\")\n",
                "\n",
                "# Add descriptions to dataframe\n",
                "df['cluster_name'] = df['cluster'].map(cluster_descriptions)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Heatmap of cluster profiles\n",
                "fig, ax = plt.subplots(figsize=(14, 8))\n",
                "\n",
                "# Clean column names for display\n",
                "display_cols = [c.replace('_per90', '').replace('_', ' ').title() for c in CLUSTERING_FEATURES]\n",
                "plot_data = cluster_zscores.copy()\n",
                "plot_data.columns = display_cols\n",
                "plot_data.index = [f\"Cluster {i}\" for i in plot_data.index]\n",
                "\n",
                "sns.heatmap(plot_data, annot=True, fmt='.2f', cmap='RdYlGn', center=0,\n",
                "            vmin=-2, vmax=2, ax=ax, cbar_kws={'label': 'Z-Score'})\n",
                "\n",
                "ax.set_title('Hierarchical Cluster Profiles (Z-Score: how different from average)', fontsize=14, fontweight='bold')\n",
                "ax.set_xlabel('Features')\n",
                "ax.set_ylabel('Cluster')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(OUTPUT_DIR / 'hierarchical_cluster_heatmap.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Visualize Clusters (2D PCA)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# PCA for 2D visualization\n",
                "pca = PCA(n_components=2)\n",
                "X_pca = pca.fit_transform(X_scaled)\n",
                "df['pca_1'] = X_pca[:, 0]\n",
                "df['pca_2'] = X_pca[:, 1]\n",
                "\n",
                "print(f\"PCA explains {pca.explained_variance_ratio_.sum()*100:.1f}% of variance\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Scatter plot\n",
                "fig, ax = plt.subplots(figsize=(12, 8))\n",
                "\n",
                "colors = plt.cm.tab10(np.linspace(0, 1, N_CLUSTERS))\n",
                "\n",
                "for cluster_id in range(N_CLUSTERS):\n",
                "    mask = df['cluster'] == cluster_id\n",
                "    count = mask.sum()\n",
                "    ax.scatter(df.loc[mask, 'pca_1'], df.loc[mask, 'pca_2'], \n",
                "               color=colors[cluster_id],\n",
                "               label=f'Cluster {cluster_id} (n={count})', alpha=0.6, s=30)\n",
                "\n",
                "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)')\n",
                "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)')\n",
                "ax.set_title('Hierarchical Clustering (PCA Projection)')\n",
                "ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left')\n",
                "ax.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(OUTPUT_DIR / 'hierarchical_cluster_scatter.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Compare with K-Means (if available)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load K-Means results if available\n",
                "kmeans_file = PROCESSED_DIR / \"forwards_clustered.csv\"\n",
                "\n",
                "if kmeans_file.exists():\n",
                "    df_kmeans = pd.read_csv(kmeans_file)\n",
                "    \n",
                "    # Merge on player\n",
                "    if PLAYER_COL and PLAYER_COL in df_kmeans.columns:\n",
                "        df_compare = df[[PLAYER_COL, 'cluster']].merge(\n",
                "            df_kmeans[[PLAYER_COL, 'cluster']],\n",
                "            on=PLAYER_COL,\n",
                "            suffixes=('_hierarchical', '_kmeans')\n",
                "        )\n",
                "        \n",
                "        # Cross-tabulation\n",
                "        cross_tab = pd.crosstab(\n",
                "            df_compare['cluster_hierarchical'], \n",
                "            df_compare['cluster_kmeans'],\n",
                "            margins=True\n",
                "        )\n",
                "        \n",
                "        print(\"üìä Hierarchical vs K-Means Cluster Comparison:\")\n",
                "        print(\"\\nCross-tabulation (rows=Hierarchical, cols=K-Means):\")\n",
                "        display(cross_tab)\n",
                "        \n",
                "        # Calculate agreement\n",
                "        from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
                "        ari = adjusted_rand_score(df_compare['cluster_hierarchical'], df_compare['cluster_kmeans'])\n",
                "        nmi = normalized_mutual_info_score(df_compare['cluster_hierarchical'], df_compare['cluster_kmeans'])\n",
                "        \n",
                "        print(f\"\\nüìà Clustering Agreement:\")\n",
                "        print(f\"  Adjusted Rand Index: {ari:.3f} (1.0 = perfect agreement)\")\n",
                "        print(f\"  Normalized Mutual Info: {nmi:.3f} (1.0 = perfect agreement)\")\n",
                "else:\n",
                "    print(\"‚ÑπÔ∏è No K-Means results found. Run notebook 03_clustering.ipynb first for comparison.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Sample Players by Cluster"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Show sample players from each cluster\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"SAMPLE PLAYERS BY CLUSTER (Hierarchical)\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "for cluster_id in range(N_CLUSTERS):\n",
                "    cluster_df = df[df['cluster'] == cluster_id]\n",
                "    print(f\"\\nCluster {cluster_id} ({len(cluster_df)} players)\")\n",
                "    print(\"-\" * 40)\n",
                "    \n",
                "    # Sort by a key metric and show top 5\n",
                "    sort_col = 'goals_per90' if 'goals_per90' in df.columns else CLUSTERING_FEATURES[0]\n",
                "    top = cluster_df.nlargest(5, sort_col)\n",
                "    \n",
                "    for _, row in top.iterrows():\n",
                "        player = row[PLAYER_COL] if PLAYER_COL else 'Unknown'\n",
                "        team = row[TEAM_COL] if TEAM_COL else ''\n",
                "        league = row[LEAGUE_COL] if LEAGUE_COL else ''\n",
                "        if league:\n",
                "            print(f\"  ‚Ä¢ {player} ({team}, {league})\")\n",
                "        else:\n",
                "            print(f\"  ‚Ä¢ {player} ({team})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Save Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save clustered data\n",
                "output_file = PROCESSED_DIR / \"forwards_hierarchical_clustered.csv\"\n",
                "df.to_csv(output_file, index=False)\n",
                "print(f\"üíæ Saved: {output_file}\")\n",
                "\n",
                "# Save model and metadata\n",
                "model_data = {\n",
                "    'linkage_matrix': Z_final,\n",
                "    'linkage_method': LINKAGE_METHOD,\n",
                "    'scaler': scaler,\n",
                "    'pca': pca,\n",
                "    'features': CLUSTERING_FEATURES,\n",
                "    'cluster_names': cluster_descriptions,\n",
                "    'cluster_profiles': cluster_profiles,\n",
                "    'cluster_zscores': cluster_zscores,\n",
                "    'n_clusters': N_CLUSTERS\n",
                "}\n",
                "\n",
                "with open(OUTPUT_DIR / \"hierarchical_clustering_model.pkl\", 'wb') as f:\n",
                "    pickle.dump(model_data, f)\n",
                "print(f\"üíæ Saved: hierarchical_clustering_model.pkl\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ‚úÖ Done!\n",
                "\n",
                "This notebook demonstrated **Hierarchical Clustering** as an alternative to K-Means.\n",
                "\n",
                "**Key takeaways:**\n",
                "- Dendrograms reveal the nested structure of player relationships\n",
                "- Ward linkage typically produces the most balanced clusters\n",
                "- Results can be compared with K-Means using Adjusted Rand Index\n",
                "\n",
                "**Next steps:**\n",
                "- Try different linkage methods (average, complete) for different cluster shapes\n",
                "- Experiment with distance metrics (cosine, Manhattan)\n",
                "- Use the dendrogram to identify sub-clusters within clusters"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}