{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üìä Football Player Analytics Pipeline\n",
                "## Notebook 1B: Scrape ALL Stat Types from FBref\n",
                "\n",
                "The initial scrape only got **standard stats**. This notebook scrapes:\n",
                "- **Shooting**: Shots, SoT%, xG, distance\n",
                "- **Passing**: Key Passes, xA, pass completion\n",
                "- **Possession**: Touches, Carries, Dribbles, Dispossessed\n",
                "- **Defense**: Tackles, Interceptions, Blocks\n",
                "- **Miscellaneous**: Aerials, Fouls\n",
                "\n",
                "This gives us 50+ features for better clustering."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import time\n",
                "import random\n",
                "from pathlib import Path\n",
                "from io import StringIO\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "from selenium import webdriver\n",
                "from selenium.webdriver.chrome.service import Service\n",
                "from selenium.webdriver.chrome.options import Options\n",
                "from selenium.webdriver.common.by import By\n",
                "from selenium.webdriver.support.ui import WebDriverWait\n",
                "from selenium.webdriver.support import expected_conditions as EC\n",
                "from webdriver_manager.chrome import ChromeDriverManager\n",
                "\n",
                "print(\"‚úÖ Libraries loaded!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Paths\n",
                "DATA_DIR = Path(\"../data\")\n",
                "RAW_DIR = DATA_DIR / \"raw\"\n",
                "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "# Stat types to scrape\n",
                "STAT_TYPES = {\n",
                "    'shooting': 'shooting',    # Shots, SoT, xG, etc.\n",
                "    'passing': 'passing',      # Key passes, xA, completion%\n",
                "    'possession': 'possession', # Touches, carries, dribbles\n",
                "    'defense': 'defense',      # Tackles, interceptions\n",
                "    'misc': 'misc',            # Aerials, fouls\n",
                "    'gca': 'gca'               # Goal/shot creating actions\n",
                "}\n",
                "\n",
                "# Leagues and their base URLs\n",
                "LEAGUES = {\n",
                "    \"Premier-League\": (\"9\", \"Premier-League\"),\n",
                "    \"La-Liga\": (\"12\", \"La-Liga\"),\n",
                "    \"Serie-A\": (\"11\", \"Serie-A\"),\n",
                "    \"Bundesliga\": (\"20\", \"Bundesliga\"),\n",
                "    \"Ligue-1\": (\"13\", \"Ligue-1\"),\n",
                "    \"Championship\": (\"10\", \"Championship\"),\n",
                "    \"Eredivisie\": (\"23\", \"Eredivisie\")\n",
                "}\n",
                "\n",
                "print(f\"üìä Will scrape {len(STAT_TYPES)} stat types\")\n",
                "print(f\"üèÜ Across {len(LEAGUES)} leagues\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_browser():\n",
                "    \"\"\"Create headless Chrome browser\"\"\"\n",
                "    chrome_options = Options()\n",
                "    chrome_options.add_argument(\"--headless=new\")\n",
                "    chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
                "    chrome_options.add_argument(\"--no-sandbox\")\n",
                "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
                "    chrome_options.add_argument(\"--window-size=1920,1080\")\n",
                "    chrome_options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\")\n",
                "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
                "    \n",
                "    service = Service(ChromeDriverManager().install())\n",
                "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
                "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
                "    return driver\n",
                "\n",
                "def get_stat_url(league_id, league_name, stat_type):\n",
                "    \"\"\"Build FBref URL for a specific stat type\"\"\"\n",
                "    base = \"https://fbref.com/en/comps\"\n",
                "    return f\"{base}/{league_id}/{stat_type}/{league_name}-Stats\"\n",
                "\n",
                "def scrape_page(driver, url):\n",
                "    \"\"\"Scrape stats table from URL\"\"\"\n",
                "    try:\n",
                "        driver.get(url)\n",
                "        WebDriverWait(driver, 15).until(EC.presence_of_element_located((By.TAG_NAME, \"table\")))\n",
                "        time.sleep(random.uniform(2, 4))\n",
                "        \n",
                "        html = driver.page_source\n",
                "        tables = pd.read_html(StringIO(html))\n",
                "        \n",
                "        # Find player stats table\n",
                "        for table in tables:\n",
                "            if isinstance(table.columns, pd.MultiIndex):\n",
                "                table.columns = ['_'.join(str(c) for c in col).strip() for col in table.columns]\n",
                "            \n",
                "            col_str = ' '.join(table.columns.astype(str)).lower()\n",
                "            if 'player' in col_str and len(table) > 10:\n",
                "                player_col = [c for c in table.columns if 'player' in c.lower()][0]\n",
                "                table = table[table[player_col] != 'Player']\n",
                "                table = table.dropna(subset=[player_col])\n",
                "                return table\n",
                "        return pd.DataFrame()\n",
                "    except Exception as e:\n",
                "        print(f\"  Error: {e}\")\n",
                "        return pd.DataFrame()\n",
                "\n",
                "print(\"‚úÖ Functions defined!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create browser\n",
                "driver = create_browser()\n",
                "print(\"‚úÖ Browser created\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Scrape all stat types for each league\n",
                "all_stats = {stat_type: [] for stat_type in STAT_TYPES.keys()}\n",
                "\n",
                "print(\"üöÄ Starting comprehensive data collection...\")\n",
                "print(f\"‚è±Ô∏è Estimated time: {len(LEAGUES) * len(STAT_TYPES) * 12 / 60:.0f} minutes\\n\")\n",
                "\n",
                "for league_name, (league_id, url_name) in LEAGUES.items():\n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"üèÜ {league_name}\")\n",
                "    print(f\"{'='*60}\")\n",
                "    \n",
                "    for stat_type, stat_url_name in STAT_TYPES.items():\n",
                "        url = get_stat_url(league_id, url_name, stat_url_name)\n",
                "        print(f\"  ‚Üí {stat_type}...\", end=\" \")\n",
                "        \n",
                "        df = scrape_page(driver, url)\n",
                "        \n",
                "        if not df.empty:\n",
                "            df['_league'] = league_name\n",
                "            df['_stat_type'] = stat_type\n",
                "            all_stats[stat_type].append(df)\n",
                "            print(f\"‚úÖ {len(df)} players\")\n",
                "            \n",
                "            # Save individual file\n",
                "            filename = RAW_DIR / f\"{league_name}_{stat_type}.csv\"\n",
                "            df.to_csv(filename, index=False)\n",
                "        else:\n",
                "            print(\"‚ùå Failed\")\n",
                "        \n",
                "        # Rate limiting\n",
                "        time.sleep(random.uniform(6, 10))\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"‚úÖ SCRAPING COMPLETE!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Close browser\n",
                "driver.quit()\n",
                "print(\"‚úÖ Browser closed\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Combine each stat type into master files\n",
                "for stat_type, dfs in all_stats.items():\n",
                "    if dfs:\n",
                "        combined = pd.concat(dfs, ignore_index=True)\n",
                "        filename = RAW_DIR / f\"all_leagues_{stat_type}.csv\"\n",
                "        combined.to_csv(filename, index=False)\n",
                "        print(f\"üíæ Saved: {filename.name} ({len(combined)} rows, {len(combined.columns)} cols)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check what we have\n",
                "print(\"\\nüìÅ Files in raw directory:\")\n",
                "for f in sorted(RAW_DIR.glob(\"*.csv\")):\n",
                "    size_kb = f.stat().st_size / 1024\n",
                "    print(f\"  {f.name} ({size_kb:.1f} KB)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ‚úÖ Now run Notebook 02 to process all the new data!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}